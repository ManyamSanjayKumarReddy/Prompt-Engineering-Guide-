{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "939eeb5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6547235a",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "MODEL = \"gpt-4.1-nano-2025-04-14\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a56663f",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    api_key = OPENAI_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa2bc2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt : list our the meaning of sanjay in 5 words\n",
      "Response : Sure! Here are five words that capture the meaning of \"Sanjay\":\n",
      "\n",
      "1. Victory\n",
      "2. Triumph\n",
      "3. Conqueror\n",
      "4. Winner\n",
      "5. Lord (or leader)\n"
     ]
    }
   ],
   "source": [
    "# basic text generation using openai api\n",
    "\n",
    "prompt = \"list our the meaning of sanjay in 5 words\"\n",
    "\n",
    "response = client.responses.create(\n",
    "    model = MODEL,\n",
    "    input = prompt\n",
    ")\n",
    "\n",
    "result = response.output[0].content[0].text\n",
    "print(f\"prompt : {prompt}\")\n",
    "print(f\"Response : {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e82db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# controlled response\n",
    "output_tokens = 150\n",
    "prompt = \"\"\"\n",
    "\n",
    "Explain **what is all about \"Attenention is all You Need\" Paper** in a clear and detailed manner. Please ensure the explanation is comprehensive but concise enough to fit within the maximum output tokens specified below.  \n",
    "**Note:** Limit your response to \"{output_tokens}\" tokens.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "response = client.responses.create(\n",
    "    model = MODEL,\n",
    "    input = prompt,\n",
    "    temperature=0.3,\n",
    "    # top_p=0.9,\n",
    "    max_output_tokens = output_tokens\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c7a70e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response : Certainly! The \"Attention Is All You Need\" paper, introduced by Vaswani et al. in 2017, revolutionized natural language processing (NLP) by proposing a new model architecture called the Transformer. Here's a clear, comprehensive overview:\n",
      "\n",
      "### Core Idea:\n",
      "The paper argues that traditional sequence models like RNNs and LSTMs, which process data sequentially, have limitations in capturing long-range dependencies and are computationally intensive. Instead, they introduce a model that relies solely on **attention mechanisms**, eliminating recurrence and convolutions.\n",
      "\n",
      "### Key Components:\n",
      "1. **Self-Attention Mechanism:**\n",
      "   - Allows the model to weigh the importance of different words in a sentence relative to each other.\n",
      "   - For each word,\n"
     ]
    }
   ],
   "source": [
    "\n",
    "result = response.output[0].content[0].text\n",
    "# print(f\"prompt : {prompt}\")\n",
    "print(f\"Response : {result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f727bfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image to text\n",
    "\n",
    "image_url = \"https://4.img-dpreview.com/files/p/E~TS590x0~articles/3925134721/0266554465.jpeg\"\n",
    "\n",
    "response = client.responses.create(\n",
    "    model = MODEL,\n",
    "    input = [{\n",
    "        \"role\" : \"user\",\n",
    "        \"content\" : [\n",
    "            {\"type\" : \"input_text\", \"text\" :\"what is this image about?\"},\n",
    "            {\n",
    "                \"type\" : \"input_image\",\n",
    "                \"image_url\" : image_url\n",
    "            }\n",
    "        ]\n",
    "    }]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3a8579a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image URL : https://4.img-dpreview.com/files/p/E~TS590x0~articles/3925134721/0266554465.jpeg\n",
      "Response : The image shows a bright yellow bird perched on a branch among green leaves. The bird appears to be in a natural outdoor setting, likely in a forest or garden. The image captures the bird in a calm and natural pose, highlighting its vibrant coloration.\n"
     ]
    }
   ],
   "source": [
    "result = response.output[0].content[0].text\n",
    "print(f\"Image URL : {image_url}\")\n",
    "print(f\"Response : {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "27899f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text to speech using OpenAI API\n",
    "\n",
    "speech_file_path = \"aivoice.mp3\"\n",
    "\n",
    "with client.audio.speech.with_streaming_response.create(\n",
    "    model = \"gpt-4o-mini-tts\",\n",
    "    voice = \"coral\",\n",
    "    input = \"I love my mom and dad. They are the best parents in the world. and I am so gratefull for them\",\n",
    "    instructions=\"Speak in a cheerful and positive tone\",\n",
    ") as response:\n",
    "    response.stream_to_file(speech_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "127bcdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# speech to text\n",
    "\n",
    "audio_file = open(\"aivoice.mp3\", \"rb\")\n",
    "\n",
    "transcription = client.audio.transcriptions.create(\n",
    "    model = \"gpt-4o-transcribe\",\n",
    "    file = audio_file\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ebd7c0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love my mom and dad. They are the best parents in the world, and I'm so grateful for them.\n"
     ]
    }
   ],
   "source": [
    "print(transcription.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6b634cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "def get_weather(latitude, longitude):\n",
    "    response = requests.get(f\"https://api.open-meteo.com/v1/forecast?latitude={latitude}&longitude={longitude}&current=temperature_2m,wind_speed_10m&hourly=temperature_2m,relative_humidity_2m,wind_speed_10m\")\n",
    "    data = response.json()\n",
    "    return data['current']['temperature_2m']\n",
    "\n",
    "tools = [{\n",
    "    \"type\": \"function\",\n",
    "    \"name\": \"get_weather\",\n",
    "    \"description\": \"Get current temperature for provided coordinates in celsius.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"latitude\": {\"type\": \"number\"},\n",
    "            \"longitude\": {\"type\": \"number\"}\n",
    "        },\n",
    "        \"required\": [\"latitude\", \"longitude\"],\n",
    "        \"additionalProperties\": False\n",
    "    },\n",
    "    \"strict\": True\n",
    "}]\n",
    "\n",
    "input_messages = [{\"role\": \"user\", \"content\": \"What's the weather like in Chennai today?\"}]\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    input=input_messages,\n",
    "    tools=tools,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ffc0788b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.7\n"
     ]
    }
   ],
   "source": [
    "tool_call = response.output[0]\n",
    "args = json.loads(tool_call.arguments)\n",
    "\n",
    "result = get_weather(args['latitude'], args[\"longitude\"])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1f2c8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_messages.append(tool_call)\n",
    "input_messages.append({\n",
    "    \"type\" : \"function_call_output\",\n",
    "    \"call_id\" : tool_call.call_id,\n",
    "    \"output\" : str(result)\n",
    "})\n",
    "\n",
    "response_2 = client.responses.create(\n",
    "    model = MODEL,\n",
    "    input = input_messages,\n",
    "    tools = tools\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ea23edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The temperature in Chennai today is approximately 33.7°C.\n"
     ]
    }
   ],
   "source": [
    "print(response_2.output[0].content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f78f87ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current temperature in Chennai is approximately 33.7°C today. If you would like more detailed weather information, please let me know!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# This is the actual tool (function) you expose to the LLM\n",
    "def get_weather(latitude, longitude):\n",
    "    # Makes a real API request to Open-Meteo to get current weather data\n",
    "    response = requests.get(\n",
    "        f\"https://api.open-meteo.com/v1/forecast\"\n",
    "        f\"?latitude={latitude}&longitude={longitude}\"\n",
    "        f\"&current=temperature_2m,wind_speed_10m\"\n",
    "        f\"&hourly=temperature_2m,relative_humidity_2m,wind_speed_10m\"\n",
    "    )\n",
    "    data = response.json()\n",
    "    return data['current']['temperature_2m']  # Just returning temperature\n",
    "\n",
    "# This tells the LLM about your tool and how to call it\n",
    "tools = [{\n",
    "    \"type\": \"function\",\n",
    "    \"name\": \"get_weather\",\n",
    "    \"description\": \"Get current temperature for provided coordinates in celsius.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"latitude\": {\"type\": \"number\"},\n",
    "            \"longitude\": {\"type\": \"number\"}\n",
    "        },\n",
    "        \"required\": [\"latitude\", \"longitude\"],\n",
    "        \"additionalProperties\": False\n",
    "    },\n",
    "    \"strict\": True\n",
    "}]\n",
    "\n",
    "# User message asking about the weather in Chennai\n",
    "input_messages = [{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"What's the weather like in Chennai today?\"\n",
    "}]\n",
    "\n",
    "# First API call to the model — it will return a tool call if needed\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4.1-mini\",  # or \"gpt-4o\", \"gpt-4.5\", etc.\n",
    "    input=input_messages,\n",
    "    tools=tools,\n",
    ")\n",
    "\n",
    "# Extract the tool call from the response\n",
    "tool_call = response.output[0]\n",
    "args = json.loads(tool_call.arguments)  # {\"latitude\": ..., \"longitude\": ...}\n",
    "\n",
    "# Run the function the model wants to call\n",
    "result = get_weather(args['latitude'], args[\"longitude\"])  # float: temperature\n",
    "\n",
    "# Now prepare full conversation history\n",
    "#   → includes the tool call + the result of the tool\n",
    "input_messages.append(tool_call)  # Add tool_call to the conversation\n",
    "\n",
    "# Add the result of the tool call, tied to its call_id\n",
    "input_messages.append({\n",
    "    \"type\": \"function_call_output\",\n",
    "    \"call_id\": tool_call.call_id,\n",
    "    \"output\": str(result)  # Must be string\n",
    "})\n",
    "\n",
    "# Second API call — the model now has the function result and gives a final answer\n",
    "response_2 = client.responses.create(\n",
    "    model = \"gpt-4.1-mini\",  # same model as before\n",
    "    input = input_messages,\n",
    "    tools = tools\n",
    ")\n",
    "\n",
    "# Print the final user-facing message\n",
    "print(response_2.output[0].content[0].text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "62f237ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embeddings \n",
    "\n",
    "words = [\n",
    "    \"king\", \"kings\", \"man\", \"woman\",\n",
    "    \"apple\", \"banana\", \"orange\", \"pear\",\n",
    "    \"castle\", \"throne\"\n",
    "]\n",
    "\n",
    "# embeddings for the words\n",
    "response = client.embeddings.create(\n",
    "    model = 'text-embedding-3-small',\n",
    "    input = words,\n",
    "    encoding_format=\"float\"\n",
    "\n",
    ")\n",
    "\n",
    "# extract the embedddings \n",
    "emeddings = [data.embedding for data in response.data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d2d8342a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dimension : 1536\n",
      "Number of embeddings : 10\n"
     ]
    }
   ],
   "source": [
    "print(f\"Embedding dimension : {len(emeddings[0])}\")\n",
    "print(f\"Number of embeddings : {len(emeddings)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389474c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Matrix (Dot Products):\n",
      "         king     kings    man      woman    apple    banana   orange   pear     castle   throne  \n",
      "king     1.0000   0.5566   0.5179   0.4143   0.2854   0.3167   0.3331   0.3303   0.4565   0.4938  \n",
      "kings    0.5566   1.0000   0.3095   0.2888   0.2420   0.1786   0.2688   0.2700   0.3337   0.4412  \n",
      "man      0.5179   0.3095   1.0000   0.7075   0.2748   0.3103   0.3075   0.3601   0.2843   0.2637  \n",
      "woman    0.4143   0.2888   0.7075   1.0000   0.3281   0.2611   0.3634   0.3922   0.2387   0.2498  \n",
      "apple    0.2854   0.2420   0.2748   0.3281   1.0000   0.4759   0.4713   0.4770   0.2978   0.2056  \n",
      "banana   0.3167   0.1786   0.3103   0.2611   0.4759   1.0000   0.4425   0.3694   0.2557   0.2352  \n",
      "orange   0.3331   0.2688   0.3075   0.3634   0.4713   0.4425   1.0000   0.3792   0.2695   0.2288  \n",
      "pear     0.3303   0.2700   0.3601   0.3922   0.4770   0.3694   0.3792   1.0000   0.2985   0.2864  \n",
      "castle   0.4565   0.3337   0.2843   0.2387   0.2978   0.2557   0.2695   0.2985   1.0000   0.4242  \n",
      "throne   0.4938   0.4412   0.2637   0.2498   0.2056   0.2352   0.2288   0.2864   0.4242   1.0000  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#pip install numpy\n",
    "\n",
    "# dot product of two vectors\n",
    "def dot_product(vec1, vec2):\n",
    "    return np.dot(vec1, vec2)\n",
    "\n",
    "# similarity maxtrix (dot product b/w all pairs of embeddings)\n",
    "similarity_matrix = np.zeros((len(words), len(words)))\n",
    "for i in range(len(words)):\n",
    "    for j in range(len(words)):\n",
    "        similarity_matrix[i][j] = dot_product(emeddings[i], emeddings[j])\n",
    "\n",
    "# print the similarity matrix with labels\n",
    "print(\"Similarity Matrix (Dot Products):\")\n",
    "print(\"         \" + \" \".join(f\"{word:<8}\" for word in words))\n",
    "for i , word in enumerate(words): #enrmuerate used to iterate over the words along with the index\n",
    "    row_values = \" \".join(f\"{similarity_matrix[i][j]:.4f}  \" for j in range(len(words)))\n",
    "    print(f\"{word:<8} {row_values}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b6d3c88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for the specific word in the similarity matrix\n",
    "\n",
    "king_queen_smilarity  = dot_product(emeddings[0], emeddings[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "39af24a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between 'king' and 'queen': 0.5566\n"
     ]
    }
   ],
   "source": [
    "print(f\"Similarity between 'king' and 'queen': {king_queen_smilarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6804eda4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4938   0.4412   0.2637   0.2498   0.2056   0.2352   0.2288   0.2864   0.4242   1.0000  \n"
     ]
    }
   ],
   "source": [
    "print(row_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edc0f7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
