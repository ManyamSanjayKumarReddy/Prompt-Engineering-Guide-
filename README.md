# Prompt Engineering Guide

This repository is a structured, practical guide for learning and mastering **Prompt Engineering** — the art and science of designing effective prompts for large language models like ChatGPT and Gemini.

## 📚 Contents

The guide is organized into clear, focused sections that progressively build your understanding:

### 1. Introduction
- Overview of prompt engineering
- Why prompting matters in LLM development

### 2. How Does AI Work
- Fundamentals of how LLMs like GPT/Gemini process and generate language
- Understanding tokenization, context windows, and model internals

### 3. OpenAI Features
- Exploring key capabilities of OpenAI models
- Role of system messages, temperature, top-p, stop sequences, and more

### 4. Principles of Prompting
- Core prompting techniques (zero-shot, few-shot, chain-of-thought)
- Instruction design best practices

### 5. Standard Text Model Practices
- Structuring prompts for consistency and safety
- Using delimiters, schemas, and multi-turn chat strategies

### 6. Deep Dive on ChatGPT
- Unique behaviors, limitations, and capabilities of ChatGPT
- Managing conversations, memory, and model responses

### 7. Gemini Basic Features
- Getting started with Google’s Gemini models
- Prompting Gemini for structured outputs, image inputs, and multimodal tasks

---


## 🛠️ Tools & Technologies

- 📓 Jupyter Notebook (100% of repo)
- 🧠 OpenAI API (ChatGPT)
- 🔮 Google Generative AI (Gemini Pro + Vision)
- 🐍 Python + Pydantic for structured responses

---

## Quick Links

- Open AI Version of the controls and techniques : https://colab.research.google.com/drive/1ths683v74Z7uviZBib5epdvPPhDj1heA?usp=sharing

## 📌 Contributing

If you find issues or have suggestions, feel free to fork this repo and raise a PR!

---


